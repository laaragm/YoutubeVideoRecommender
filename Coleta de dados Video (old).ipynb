{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletor da página de vídeo\n",
    "Vídeos retornados pelas queries que nos interessam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n",
    "import requests as rq\n",
    "import bs4 as bs4\n",
    "import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coleta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('parsed_videos.json', lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links =  df['link'].unique()\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com{link}'\n",
    "\n",
    "for link in links:\n",
    "    formatted_url = url.format(link=link)\n",
    "    print(formatted_url)\n",
    "    response = rq.get(formatted_url)\n",
    "    \n",
    "    # pega uma expressão regular (nesse caso tudo que vier depois do sinal de igual na string do link) e pegamos o primeiro\n",
    "    # grupo de seleção (basicamente o identificador do vídeo)\n",
    "    link_name = re.search('v=(.*)', link).group(1)\n",
    "    \n",
    "    with open('./dados_brutos/video_{}.html'.format(link_name), 'w+') as output:\n",
    "        output.write(response.text)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parsed_video_info.json', 'w+') as output:\n",
    "    for video in tqdm.tqdm_notebook(sorted(glob.glob('./dados_brutos/video*'))):\n",
    "        with open(video, 'r+') as inp:\n",
    "            page = inp.read()\n",
    "            parsed = bs4.BeautifulSoup(page, 'html.parser') #html.parser pois estamos processando um arquivo html\n",
    "            \n",
    "            #buscando todas as tags que tenham uma determinada class\n",
    "            class_watch = parsed.find_all(attrs={'class':re.compile(r'watch')})\n",
    "            id_watch = parsed.find_all(attrs={'id':re.compile(r'watch')}) \n",
    "            channel = parsed.find_all('a', attrs={'href':re.compile(r'channel')}) #link do canal\n",
    "            meta = parsed.find_all('meta') #tags meta que tem algumas infos sobre o vídeo\n",
    "            \n",
    "            data = {}\n",
    "            for element in class_watch:\n",
    "                column_name = \"_\".join(element['class']) #valor da classe = nome do atributo nos dados \n",
    "                if 'clearfix' in column_name: #clearfix pra não pegar duplicados (característica específica da página)\n",
    "                    continue\n",
    "                data[column_name] = element.text.strip() \n",
    "                \n",
    "            for element in id_watch:\n",
    "                column_name = \"_\".join(element['id'])\n",
    "                #if 'clearfix' in column_name: \n",
    "                    #continue\n",
    "                data[column_name] = element.text.strip()\n",
    "                \n",
    "            for element in meta:\n",
    "                column_name = element.get('property')\n",
    "                if column_name is not None:\n",
    "                    data[column_name] = element['content']\n",
    "                    \n",
    "            for link_number,element in enumerate(channel):\n",
    "                data['channel_link_{}'.format(link_number)] = element['href']\n",
    "                \n",
    "            output.write(\"{}\\n\".format(json.dumps(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = class_watch[1]\n",
    "print(element['class'])\n",
    "print('_'.join(element['class']))\n",
    "element.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = meta[4]\n",
    "print(element)\n",
    "element['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = channel[0]\n",
    "print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('parsed_video_info.json', lines=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 166)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['watch-title', 'watch-view-count', 'watch-time-text', 'content-watch-info-tag-list', 'watch7-headline',\n",
    "                   'watch7-user-header', 'watch8-sentiment-actions', 'og:image', 'og:image:width', 'og:image:height',\n",
    "                   'og:description', 'og:video:width', 'og:video:height', 'og:video:tag', 'channel_link_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[selected_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.feather: compatível com outras linguagens e por ser binário tem um carregamento mais rápido (também é possível\n",
    "#fazer o carregamento em paralelo)\n",
    "df[selected_columns].to_feather('raw_data.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para posteriormente adicionarmos labels desejados\n",
    "df[selected_columns].to_csv('raw_data_sem_labels')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
