{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletor da página de busca do Youtube\n",
    "Precisamos de pegar a página que retorna os resultados da busca (entra com as keywords e faz a ordenação pelos mais recentes) e precisamos de pegar a página de cada um dos vídeos retornados a partir da busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n",
    "import requests as rq\n",
    "import bs4 as bs4 #beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['computer+organization+and+architecture', 'computer+organization', 'computer+architecture']\n",
    "url = 'https://www.youtube.com/results?search_query={query}&sp=CAI%253D&p={page}' #outra opção: utilizar selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coleta dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    for page in range(1,101):\n",
    "        formatted_url = url.format(query=query, page=page)\n",
    "        print(formatted_url)\n",
    "        response = rq.get(formatted_url) #GET request\n",
    "        \n",
    "        with open('./dados_brutos/{}_{}.html'.format(query, page), 'w+') as output:\n",
    "            output.write(response.text)\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrator de dados da página de busca do Youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento dos dados brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    for page in range(1,101):\n",
    "        with open('./dados_brutos/{}_{}.html'.format(query, page), 'r+') as data:\n",
    "            page_html = data.read()\n",
    "            \n",
    "            parsed = bs4.BeautifulSoup(page_html)\n",
    "            \n",
    "            #encontra todas as tags com o nome passado por parâmetro. Passamos 'a' pois são as tags link\n",
    "            tags = parsed.findAll('a')\n",
    "            \n",
    "            for instance in tags:\n",
    "                # aria-describedby: encontra inspecionando o elemento do link; pegamos ele pois sabemos que se trata de um vídeo\n",
    "                if instance.has_attr('aria-describedby'):\n",
    "                    link = instance['href']\n",
    "                    title = instance['title']\n",
    "                    with open('parsed_videos.json', 'a+') as output: # a+: adiciona linhas ao arquivo\n",
    "                        video_info = {'link': link, 'title': title, 'query': query}\n",
    "                        output.write('{}\\n'.format(json.dumps(video_info)))           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação do resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_json('parsed_videos.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('title')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
